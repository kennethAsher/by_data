#####测试#####
input_path = hdfs:///test/spark/input
input_file = hdfs:///hive/imp/organ_add_data/
output_path = hdfs:///test/pyspark/demo/output6/



#####清洗#####路径
#原始裁判文书位置
organ_data_path = hdfs:///hive/imp/organ_data/
#原始补充数据位置
organ_add_data_path = hdfs:///hive/imp/organ_add_data/
#补充数据完成补充之后的路径
add_data_path = hdfs:///hive/imp/add_data/




#####工具#####路径
#级别案由原文件存放位置
cause_of_action_path = hdfs:///hive/by/pg_data/pg_sm_cause_of_action/pg_sm_cause_of_action.txt


#####配置名称
#Spark SupplementAddData的appName
supplement_add_data_appname = SupplementData
#清洗castparty文书的appName
Case_party_appname = CaseParty